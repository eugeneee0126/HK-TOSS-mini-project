import time
from playwright.sync_api import sync_playwright
import pandas as pd

def main():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        context = browser.new_context()
        page = context.new_page()

        # 1. ì¹´ì¹´ì˜¤ë§µ ì ‘ì†
        page.goto('https://map.kakao.com/')
        print("âœ… ì¹´ì¹´ì˜¤ë§µ ì ‘ì† ì™„ë£Œ")

        # 2. ê²€ìƒ‰ì°½ì— "ì¶©ì •ë¡œì—­ ë§›ì§‘" ì…ë ¥
        page.wait_for_selector('input#search\\.keyword\\.query')
        page.fill('input#search\\.keyword\\.query', 'ì¶©ì •ë¡œì—­ ë§›ì§‘')
        page.keyboard.press('Enter')
        print("âœ… ì¶©ì •ë¡œì—­ ë§›ì§‘ ê²€ìƒ‰ ì™„ë£Œ")

        # 3. ê²€ìƒ‰ ê²°ê³¼ ê¸°ë‹¤ë¦¬ê¸°
        page.wait_for_selector('ul#info\\.search\\.place\\.list')

        # 4. dimmedLayer ë‹«ê¸° (ì„ íƒ ì‚¬í•­)
        try:
            page.wait_for_selector('div#dimmedLayer', timeout=3000)
            page.click('div#dimmedLayer')
            print("âœ… dimmedLayer ë‹«ìŒ")
        except:
            print("âœ… dimmedLayer ì—†ìŒ")

        all_store_menu_data = []
        num_stores_to_crawl = 50
        crawled_stores_count = 0
        more_button_clicked = False

        while crawled_stores_count < num_stores_to_crawl:
            print(f"\n--- í˜„ì¬ê¹Œì§€ {crawled_stores_count}ê°œ ê°€ê²Œ í¬ë¡¤ë§ ì™„ë£Œ ---")

            store_list_selector = 'ul#info\\.search\\.place\\.list li'
            page.wait_for_selector(store_list_selector)
            store_items = page.query_selector_all(store_list_selector)
            print(f"âœ… í˜„ì¬ í˜ì´ì§€ì— {len(store_items)}ê°œì˜ ê°€ê²Œ ë°œê²¬")

            for i, store_item in enumerate(store_items):
                if crawled_stores_count >= num_stores_to_crawl:
                    break

                store_index_on_page = i + 1
                print(f"\n--- {crawled_stores_count + 1}ë²ˆì§¸ ê°€ê²Œ (í˜„ì¬ í˜ì´ì§€ ìˆœë²ˆ {store_index_on_page}) í¬ë¡¤ë§ ì‹œì‘ ---")
                new_page = None
                try:
                    more_view_button = store_item.query_selector('a.moreview')
                    if more_view_button:
                        with context.expect_page() as new_page_info:
                            more_view_button.click()
                        new_page = new_page_info.value
                        print("âœ… ìƒì„¸ë³´ê¸° í˜ì´ì§€ ì—´ë¦¼")

                        new_page.wait_for_selector('h3.tit_place', timeout=10000)

                        try:
                            store_name_raw = new_page.inner_text('h3.tit_place')
                            store_name = store_name_raw.replace("ì¥ì†Œëª…", "").strip()
                            print(f"ğŸ¢ ê°€ê²Œ ì´ë¦„: {store_name}")

                            store_menu_data = []
                            menu_tab = new_page.query_selector('a[role="tab"]:has-text("ë©”ë‰´")')
                            if menu_tab:
                                menu_tab.click()
                                new_page.wait_for_selector('ul.list_goods > li', timeout=10000)
                                menu_items = new_page.query_selector_all('ul.list_goods > li')
                                print("âœ… ë©”ë‰´ íƒ­ í´ë¦­ ë° ë©”ë‰´ ì •ë³´ ë¡œë”© ì™„ë£Œ")

                                for item in menu_items:
                                    try:
                                        title_element = item.query_selector('strong.tit_item')
                                        price_element = item.query_selector('p.desc_item')

                                        title = title_element.inner_text().strip() if title_element else None
                                        price = price_element.inner_text().strip() if price_element else None

                                        if title:
                                            store_menu_data.append({'ê°€ê²Œì´ë¦„': store_name, 'ë©”ë‰´ëª…': title, 'ê°€ê²©': price})
                                    except Exception as e:
                                        print(f"âš ï¸ ë©”ë‰´ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                            else:
                                print("âš ï¸ ë©”ë‰´ íƒ­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                            all_store_menu_data.extend(store_menu_data)
                            crawled_stores_count += 1
                            if new_page and not new_page.is_closed():
                                new_page.close()

                        except Exception as e:
                            print(f"âŒ ê°€ê²Œ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                            if new_page and not new_page.is_closed():
                                new_page.close()
                    else:
                        print("âš ï¸ ìƒì„¸ë³´ê¸° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                except Exception as e:
                    print(f"âŒ ê°€ê²Œ ìƒì„¸ë³´ê¸° í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨ (í˜„ì¬ í˜ì´ì§€ ìˆœë²ˆ {store_index_on_page}): {e}")
                    if new_page and not new_page.is_closed():
                        new_page.close()

                if crawled_stores_count >= num_stores_to_crawl:
                    break

                time.sleep(1)  # ì ì‹œ ëŒ€ê¸°

            if crawled_stores_count < num_stores_to_crawl:
                if not more_button_clicked:
                    try:
                        more_button_selector = '#info\\.search\\.place\\.more'
                        page.wait_for_selector(more_button_selector, timeout=5000)
                        page.click(more_button_selector)
                        print("â¡ï¸ 'ì¥ì†Œ ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­")
                        page.wait_for_selector('ul#info\\.search\\.place\\.list', timeout=10000)  # ë‹¤ìŒ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                        time.sleep(2)  # í˜ì´ì§€ ë¡œë”© í›„ ì ì‹œ ëŒ€ê¸°
                        more_button_clicked = True
                    except Exception as e:
                        print(f"âš ï¸ 'ì¥ì†Œ ë”ë³´ê¸°' ë²„íŠ¼ ì—†ìŒ ë˜ëŠ” í´ë¦­ ì‹¤íŒ¨: {e}")
                        # 'ì¥ì†Œ ë”ë³´ê¸°' ë²„íŠ¼ì´ ì—†ìœ¼ë©´ í˜ì´ì§€ ë²ˆí˜¸ë¡œ ì´ë™ ì‹œë„
                        break
                else:
                    # í˜ì´ì§€ ë²ˆí˜¸ë¡œ ì´ë™
                    try:
                        next_page_num = (crawled_stores_count // 15) + 2  # ë‹¤ìŒ í˜ì´ì§€ ë²ˆí˜¸ ê³„ì‚° (15ê°œì”© ë¡œë“œ ê°€ì •)
                        next_page_selector = f'#info\\.search\\.page\\.no{next_page_num}'
                        page.wait_for_selector(next_page_selector, timeout=5000)
                        page.click(next_page_selector)
                        print(f"â¡ï¸ í˜ì´ì§€ {next_page_num} í´ë¦­")
                        page.wait_for_selector('ul#info\\.search\\.place\\.list', timeout=10000)  # ë‹¤ìŒ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                        time.sleep(2)  # í˜ì´ì§€ ë¡œë”© í›„ ì ì‹œ ëŒ€ê¸°
                    except Exception as e:
                        print(f"âš ï¸ í˜ì´ì§€ {next_page_num} ë²„íŠ¼ ì—†ìŒ ë˜ëŠ” í´ë¦­ ì‹¤íŒ¨: {e}")
                        break  # ë” ì´ìƒ í˜ì´ì§€ ë²„íŠ¼ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ

    

        # 9. í¬ë¡¤ë§ëœ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ ë° CSV ì €ì¥
        if all_store_menu_data:
            df = pd.DataFrame(all_store_menu_data)
            print("\nğŸ“Š í¬ë¡¤ë§ëœ ì „ì²´ ë°ì´í„°í”„ë ˆì„:")
            print(df)
            csv_filename = "chungjeongno_top50_restaurants_menu.csv"
            try:
                df.to_csv(csv_filename, encoding='utf-8-sig', index=False)
                print(f"\nğŸ’¾ ë°ì´í„°ë¥¼ '{csv_filename}'ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        else:
            print("\nâš ï¸ í¬ë¡¤ë§ëœ ë©”ë‰´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()